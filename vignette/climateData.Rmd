---
title: "Generating ASMR estimates for North Area BGC units"
author: "Hardy Griesbauer"
date: "17/09/2019"
output:
  word_document: default
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Description of choosing climate stations for BGC units in the North Area

Below is R code and description used to select climate station data to generate ASMR estimates for 
various BGC units in the North Area.

```{r message=FALSE}
# Load libraries
library(forestDroughtTool)
library(tidyverse)
library(weathercan)
library(ggplot2)
library(here)
library(magrittr)
```

## What are the BGC units of interest in the North Area?

What units do we want to generate drought hazard estimates for?

```{r}
# North Area BGC units are saved in .rda file
load(here("dat","northBGC.rda"))
northBGC

```

## What ECCC climate stations exist for these units?

Using a bunch of different packages, we can query the ECCC climate station data and see which ones are located in the BGC units of interest.

```{r}

# DON'T RUN - Takes a long time, instead use load()
# # Step 1 - Select stations in BC with daily data and assign to 'stn'
# stn<-
#   weathercan::stations %>% 
#   dplyr::filter(prov=="BC" & interval=="day") %>%  
#   
# # Step 2 - Convert to a spatial file and merge with BGC units (this will take awhile!)
#   sf::st_as_sf(coords=c("lon","lat")) %>% # convert to spatial file
#   sf::st_set_crs(4326) %>% # set to WGS1984 datum
#   bcmaps::transform_bc_albers() %>% # set to BC albers projection
#   sf::st_join(bcmaps::bec()[,"MAP_LABEL"]) %>%  # merge with BEC
#   sf::st_drop_geometry() %>%  # drop geometry
# 
# # Step 3 - Merge with BGC units of interest (above)
#   dplyr::filter(MAP_LABEL%in%northBGC) %>% # filter for BGC units of interest
#   dplyr::mutate(length=end-start+1) %>% # create a column to show record length
#   dplyr::arrange(MAP_LABEL,desc(length)) %>% 
#   dplyr::select(station_name,station_id,bgc=MAP_LABEL,start,end,length)
# 
# # step 4 save stn so you don't have to run above lines of code
#   save(stn,file=here("dat","stationList.rda"))

# Load station data compiled from above lines of code
  load(here("dat","stationList.rda"))

# Print to screen
  stn
```

## Download climate data
Need to download climate data for stations.  This will take a long time, so I saved the downloaded data into an .rda file.

* Note that in the future we will want to update some of the station data with cleaned data from Vanessa.  This will take me some time!*

I printed out the station list, and manually selected stations (not shown) that have long records that span the 1961-1990 climate normal period, as much as possible.  In some cases, we may want to join records.

```{r}
# Row numbers of stations of interest
stnRow=c(1,   2,   4,  11,  12,  15,  17,  21,  22,  36,  37,  39,  66,  67,
         72,  73,  85,  86,  87,  93, 108, 109, 123, 137, 143,
         144, 149, 150, 151, 153)

# Don't run - takes a long time.  Use load() instead
# Download data using the stnRow (this can take a long time!)
# climData<-
#   weather_dl(station_ids=stn$station_id[stnRow],interval="day") %>%
#   
#   # format climate data (see below for more information)
#   select(stn=station_name,date,tmn=min_temp,tmx=max_temp,ppt=total_precip,year,month,day)

# save(climData,file=here("dat","climData.rda"))

load(here("dat","climData.rda"))

```

## Clean climate station data
We need to process missing values in the daily climate data.  For this project, we:
- omitted any years with >10 consecutive missing data in any climate variable;and
- imputed missing data using adjacent values (closest data before and after missing value)
- Leap years have 366 days, so we removed February 29 from those years to keep number of days to 365.

```{r message=FALSE}

# DON'T RUN - this takes a long time, use load() instead

# cleanECData() for each station
# x1<-by(INDICES=climData$stn,function(x) cleanECData(x),data=climData) 
# 
# # Formatting
# climData_cleaned<-dplyr::bind_rows(x1,.id="id") 
# climData_cleaned$stn<-names(x1)[as.numeric(climData_cleaned$id)]
# rm(x1)

# # Format date columns
# climData_cleaned%<>%
#   mutate(month=as.integer(month)) %>% 
#   mutate(day=as.integer(day)) %>% 
#   mutate(year=as.integer(year)) %>% 
#   mutate(date=paste(year,month,day,sep="-"))

# Rename columns to make it easier to pass to asmrCalc()
# climData_cleaned%<>%
#   rename(!!'tmn':=tmn_filled,!!'ppt':=ppt_filled,!!'tmx':=tmx_filled)

# save(climData_cleaned,file=here("dat","climData_cleaned.rda"))

# Load cleaned EC climate data from above lines of code
load(here("dat","climData_cleaned.rda"))

# Summarize station data 
climData_cleaned %>%
  group_by(stn,year) %>%
  summarise(n()) %>%
  ungroup() %>%
  group_by(stn) %>%
  summarise(Num.years=n(),start=min(year),end=max(year))

```

## Figure showing data coverage for each station
It might be useful to produce a figure showing climate data coverage for each station and BGC unit.

```{r}

climData_cleaned %>% 
  group_by(stn,year) %>% 
  summarise(days=n()) %>% 
  inner_join(stn,by=c("stn"="station_name")) %>% 
  select(stn,year,days,bgc) %>% 
  ungroup() %>% 
  mutate(ID=paste(bgc,stn,sep=":")) %>% 
  ggplot(aes(year, ID)) +
  geom_tile(aes(fill = days))+
  theme(legend.position = "none")+
  theme(axis.text.x = element_text(angle = 90,vjust = 0.5))




```

## Select stations and climate data to run model
Generally, we have been summarising site ASMR using 10 years of daily climate data.  The rationale for this is that we want to keep data consistent between BGC units, and we need to be able to use stations with relatively sparse data (ie. 10 years).

Based on a conversation with Vanessa, we've decided on the following:

1. Restrict data to 1940 and 1990.  Data pre-1940 may have measurement errors, and post-1990 is starting to get into the "climate change" realm.
2. Ideally, restrict years to 1961-1990 normal period.  If number of years available is less than 10, then use years from 1940-1990.
3. Select 10 years randomly from within the dataset.  If there are less than 10 years of data within 1961-1990 dataset, then use all the years from 1961-1990, and add random years' data from 1940-1960 until number of years = 10.

This is all taken care of in the asmrSelect() function in the forestDroughtTool package.

```{r}

# Need to change Pink Mountain2 to Pink Mountain, to concatenate the datasets
climData_cleaned %<>% 
  mutate(stn=replace(stn,stn=="PINK MOUNTAIN 2","PINK MOUNTAIN"))



```

### Use data for ICHwk1 and ICHvk2
Dome creek and Crescent Spur stations are located near the valley bottoms in the Robson Valley, near the boundary between ICH and SBSvk.  Given their proximity to the BGC unit boundary, and based on expert ecologist opinion (ie., Craig and Bruce), we decided to use these stations to represent adjacent ICH variants.  Same for Blue River station.

```{r}

stations %>% 
  filter(str_detect(station_name,'DOME CREEK|CRESCENT SPUR|BLUE RIVER')) %>% 
  filter(interval=="day")

```

Blue River North (station id = 1238) and Dome Creek (station id = 581) look to have good data.  Crescent Spur only has data from 1992 - so we won't use this station for now.

Blue River A does not have adequate data!

Next step is to extract clean/data for Dome Creek and Blue River North and compile it with the rest of the climate dataset.

```{r}

# Don't run this -takes a long time.  Use load() instead  
# climData2<-
#    weather_dl(station_ids=c(581,1238), interval="day") %>% 
# select(stn=station_name,date,tmn=min_temp,tmx=max_temp,ppt=total_precip,year,month,day)

# cleanECData() for each station

# dome<-data.frame(stn="DOME CREEK",cleanECData(filter(climData2,stn=="DOME CREEK"))) %>% 
#   mutate(bgc="ICHvk2") %>% 
#   mutate(stn_id=581) %>% 
#   mutate(id=31)
# 
# blue<-data.frame(stn="BLUE RIVER",cleanECData(filter(climData2,stn=="BLUE RIVER NORTH"))) %>% 
#   mutate(bgc="ICHwk1") %>% 
#   mutate(stn_id=1238) %>% 
#   mutate(id=32)
# 
# x1<-rbind(blue,dome)
# 
# # Format date columns
#  x1%<>%
#    mutate(month=as.integer(month)) %>% 
#    mutate(day=as.integer(day)) %>% 
#    mutate(year=as.integer(year)) %>% 
#    mutate(date=paste(year,month,day,sep="-")) %>% 
# 
#    # Rename columns to make it easier to pass to asmrCalc()
#    rename(!!'tmn':=tmn_filled,!!'ppt':=ppt_filled,!!'tmx':=tmx_filled) %>% 
#    
#    # select columns
#    dplyr::select(names(climData_cleaned))
#      
# 
#  # Merge with climData_cleaned
#  climData_cleaned=rbind(climData_cleaned,x1)
#  save(climData_cleaned,file=here::here("dat","climData_cleaned.rda"))
 
# Designate stations to use:
stnList=c(1432,547,1397,569,568,482,664,601,623,588,496,631,1423,564,1429,1238,581)

# Bring in Dome Creek and Blue River station data as well
stnID<-
  stations %>% 
  filter(station_id==581|station_id==1238) %>% 
  filter(interval=="day") %>% 
  mutate(bgc="ICHwk1") %>% 
  mutate(bgc=replace(bgc,station_id==581,"ICHvk2")) %>%
  mutate(station_name=replace(station_name,station_id==1238,"BLUE RIVER")) %>% 
  mutate(length=end-start+1) %>% 
  select(station_name,station_id,bgc,start,end,length) %>% 
  rbind(stn[stn$station_id%in%stnList,]) # rbind with the rest of the stations
  

# Print out stations used in ASMR
stnID

```


## Calculate ASMR for the stations

Now let's run a loop to generate the dataset and export it.

```{r}

# Don't run this takes a long time, use load () instead
# for (j in 1:nrow(stnID)) {
# 
#   # Get ASMR summaries for the station
#   x<-
#     climData_cleaned %>%
#     filter(stn==stnID$station_name[j]) %>%
#     asmrCalc() %>%
#     asmrSelect()
# 
#   # Extract ASMR mean and SD
#   asmr<-
#     x$asmr %>%
#     mutate(bgc=stnID$bgc[j]) %>%
#     dplyr::select(bgc,month,everything())
# 
#   # Extract years used to calculate ASMR
#   yearASMR<-
#     c(stnID$bgc[j],x$years)
# 
#   # Compile asmr into data frame
#   if(j==1) {asmrNorth2=asmr} else {asmrNorth2=rbind(asmrNorth2,asmr)}
# 
#   # Compile years into data frame
#   if(j==1) {years=yearASMR} else {years=rbind(years,yearASMR)}
# 
#   if (j==nrow(stnID)) {
# 
#     years=as.data.frame(years)
#     names(years)=c("bgc",paste("year",1:10,sep=""))
#     years<-as_tibble(years)
# 
#   }
# 
# }
# 
#   save(asmrNorth2,file=here::here("dat","asmrNorth2.rda"))
#   save(years,file=here::here("dat","years.rda"))

load(here::here("dat","asmrNorth2.rda"))
load(here::here("dat","years.rda"))

```

# ANALYSIS

## Generate annual ASMR estimates by BGC unit

```{r}

# Generate annual AET/PET for five sites by BGC unit
asmrANNUAL<-
  asmrNorth2 %>% 
  dplyr::select(bgc,month,contains(".mean")) %>% 
  group_by(bgc) %>% 
  summarise_at(vars(contains(".mean")),mean) 

# Print asmrANNUAL
asmrANNUAL

```

## BGC units without climate data
For the following BGC units that don't have climate data, can we lump any BGC units together (i.e., create ASMR estimates for one BGC unit using ASMR from another):

```{r}
northBGC[!northBGC%in%asmrANNUAL$bgc]

```

### Amalgamate drought estimates by subzone (not variant) for variants missing climate data
Create a list of BGC units that have ASMR data that we can use to provide estimates for climate-missing BGC units:

```{r}
# Create a function to assign subzones to their respective variant with climate data

# bgcMissing is the BGC unit that is missing climate data
# bgcComplete is the BGC unit that you want to use the ASMR values for bgcMissing

bgc.subF<-function(bgcMissing,bgcComplete) { 
  
  return(data.frame(bgc=bgcMissing,
              asmrANNUAL[asmrANNUAL$bgc%in%bgcComplete,2:ncol(asmrANNUAL)]
            ))
    }

# Now run the function for BGC units missing data

asmrANNUAL2<-
  bgc.subF("SBSwk3","SBSwk1") %>% 
  rbind(bgc.subF("ESSFmv4","ESSFmv2")) %>% 
  rbind(bgc.subF("ESSFmv3","ESSFmv2")) %>% 
  rbind(bgc.subF("ESSFmv1","ESSFmv2")) %>% 
  rbind(bgc.subF("SBSmc1","SBSmc2")) %>% 
  rbind(bgc.subF("SBSmc3","SBSmc2")) %>% 
  rbind(bgc.subF("ICHmc1","ICHmc2")) %>%
  rbind(bgc.subF("ESSFwk2","ESSFwk1")) %>% 
  rbind(bgc.subF("ICHwk3","ICHwk1")) %>% 
  rbind(bgc.subF("ICHwk4","ICHwk1")) %>% 
  rbind(asmrANNUAL)
  
# Print results to document
asmrANNUAL2
  

```

Now let's see which bgc units are missing data:

```{r}
northBGC[!northBGC%in%asmrANNUAL2$bgc]
```


```{r}



knitr::kable(asmrANNUAL2,digits=2)
# write.csv(asmrANNUAL,file="asmrANNUAL.csv")

# Classify
asmrCut<-function(x) cut(x,breaks=c(0,asmrClass$asmrUL),labels=asmrClass$class)

asmrNorthClass<-
  asmrANNUAL2 %>% 
  mutate_if(is.numeric,asmrCut) %>% 
  mutate(bgc=as.character(bgc)) %>%  
  arrange(bgc) 
  
  knitr::kable(asmrNorthClass)


```

## Final task: Export data and save it to 

```{r}
# Create data to export as a list
stnYears<-
  stnID %>% 
  dplyr::select(stn=station_name,stnID=station_id,bgc) %>% 
  inner_join(years,by="bgc")

asmrNorth<-list(current=list(class=asmrNorthClass,asmr=asmrANNUAL2,stnYears),future=list())


```
